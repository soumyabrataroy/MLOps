{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "running_mlflow_on_colab2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8RGk73v55fQ",
        "outputId": "cc91d423-ce61-4e09-c9d6-f54c32149a68"
      },
      "source": [
        "!pip install mlflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/69/c6b3911ccb421adc779390ca2ea54cb888a54e282d50e8d20ce751b5c7ab/mlflow-1.12.1-py3-none-any.whl (13.9MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9MB 316kB/s \n",
            "\u001b[?25hCollecting docker>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/b7/eb7b7138bb5e6d28cf84fa586fe594619ca097b6207caa5f2ebe0c66a4ed/docker-4.4.0-py2.py3-none-any.whl (146kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 50.3MB/s \n",
            "\u001b[?25hCollecting gunicorn; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.3.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.8.1)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.19.4)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/d5/8a046d683c2cc084b6a502812827ede69b1064f95d93f94b83f809b21723/prometheus_flask_exporter-0.18.1.tar.gz\n",
            "Collecting databricks-cli>=0.8.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/88/ae1f78cf582b707c605c77df49b4c8786a4465edc51adb25d2f98ef4c4de/databricks-cli-0.14.1.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.3)\n",
            "Collecting alembic<=1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/e9/359dbb77c35c419df0aedeb1d53e71e7e3f438ff64a8fdb048c907404de3/alembic-1.4.1.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 49.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.12.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (7.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.1.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.13)\n",
            "Collecting querystring-parser\n",
            "  Downloading https://files.pythonhosted.org/packages/88/6b/572b2590fd55114118bf08bde63c0a421dcc82d593700f3e2ad89908a8a9/querystring_parser-1.2.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.3.0)\n",
            "Collecting azure-storage-blob\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/5d/0bb4ed37da2523c393789b1d8ecbf56b1d35fa344af30fe423da2c06cbe9/azure_storage_blob-12.6.0-py2.py3-none-any.whl (328kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.1.2)\n",
            "Collecting gitpython>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 50.1MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 50.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.6/dist-packages (from gunicorn; platform_system != \"Windows\"->mlflow) (50.3.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2020.12.5)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow) (0.9.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.7)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.5MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mlflow) (2018.9)\n",
            "Collecting azure-core<2.0.0,>=1.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/4b/ea7faaafac956a168ab9a95a7ebe583f9d308e8332a68af0ed3128ef520c/azure_core-1.9.0-py2.py3-none-any.whl (124kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 57.2MB/s \n",
            "\u001b[?25hCollecting msrest>=0.6.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/f5/9e315fe8cb985b0ce052b34bcb767883dc739f46fadb62f05a7e6d6eedbe/msrest-0.6.19-py2.py3-none-any.whl (84kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.6MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/de/7054df0620b5411ba45480f0261e1fb66a53f3db31b28e3aa52c026e72d9/cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 49.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (2.11.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (1.0.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic<=1.4.1->mlflow) (1.1.1)\n",
            "Collecting isodate>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.10->azure-storage-blob->mlflow) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-storage-blob->mlflow) (1.14.4)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-storage-blob->mlflow) (3.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->mlflow) (2.20)\n",
            "Building wheels for collected packages: prometheus-flask-exporter, databricks-cli, alembic\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.1-cp36-none-any.whl size=17159 sha256=d3aa3ad4967228f8fbd389db0dc44f268fd37c9a266f8c7cb00064175c081264\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/1f/b8/66bd9bc3a9d6c6987ff6c4dfeb6f1fe97b5a0e5ed5849c0437\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.14.1-cp36-none-any.whl size=100579 sha256=ef37a3ab862e1b6e215555da7f2641eb9ce0bf85a0e3c85711a5224cb97896c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/91/ac/5d417ee5ccbb76c8cca096cf4cfb9ed9d49d889d1d1ca0fc39\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=936950f3427a273480643c273147a0611e76325f05338e73d74c1fd28db7fa22\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/07/f7/12f7370ca47a66030c2edeedcc23dec26ea0ac22dcb4c4a0f3\n",
            "Successfully built prometheus-flask-exporter databricks-cli alembic\n",
            "Installing collected packages: websocket-client, docker, gunicorn, prometheus-flask-exporter, databricks-cli, Mako, python-editor, alembic, querystring-parser, azure-core, isodate, msrest, cryptography, azure-storage-blob, smmap, gitdb, gitpython, mlflow\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.1 azure-core-1.9.0 azure-storage-blob-12.6.0 cryptography-3.3.1 databricks-cli-0.14.1 docker-4.4.0 gitdb-4.0.5 gitpython-3.1.11 gunicorn-20.0.4 isodate-0.6.0 mlflow-1.12.1 msrest-0.6.19 prometheus-flask-exporter-0.18.1 python-editor-1.0.4 querystring-parser-1.2.4 smmap-3.0.4 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYy1MhVt6aoE",
        "outputId": "1227fbdb-0688-4dfc-a808-0f8543b4859b"
      },
      "source": [
        "!pip install pyngrok\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/63/e086f165125e9bf2e71c0db2955911baaaa0af8947ab5c7b3771bdf4d4d5/pyngrok-5.0.0.tar.gz\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyngrok) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.0.0-cp36-none-any.whl size=18781 sha256=34a381d52cae29a528b8f952c8bfca8d3077fd47afcccb5558b809f8645bb279\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/df/23/af8dde08c3fcdc7b966adcacef48ab29aa3b0b1860df5d2b79\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2n0_4536uB8"
      },
      "source": [
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsSSLHc166-m"
      },
      "source": [
        "from pyngrok import ngrok\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYP93dOY6_Hg"
      },
      "source": [
        "ngrok.kill()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78RMcjbj7D-0",
        "outputId": "820f21cc-b418-4651-cf83-848d425b3fa3"
      },
      "source": [
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_sn7cG_7Lcu",
        "outputId": "0ca1975f-463d-4ea4-f455-2b4b2367cb23"
      },
      "source": [
        "print(\"MLflow UI \", ngrok_tunnel.public_url)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLflow UI  https://a555ad5d48fa.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msB9UJ9C7Pbp",
        "outputId": "73bca601-8e4e-4ab8-ada4-f1a6fd76a33b"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "\r\n",
        "    mlflow.set_experiment(experiment_name=\"mlflow demo\")\r\n",
        "    \r\n",
        "    training_data = pd.read_csv('https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/storepurchasedata.csv')\r\n",
        "    print(\"loaded training data\")\r\n",
        "\r\n",
        "    training_data.describe()\r\n",
        "    mlflow.log_param(\"training percentage\",60)\r\n",
        "\r\n",
        "    mlflow.log_param(\"dataset shape\",training_data.shape)\r\n",
        "    \r\n",
        "    X = training_data.iloc[:, :-1].values\r\n",
        "    y = training_data.iloc[:,-1].values\r\n",
        "    \r\n",
        "    from sklearn.model_selection import train_test_split\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =.4,random_state=0)\r\n",
        "    \r\n",
        "    from sklearn.preprocessing import StandardScaler\r\n",
        "    sc = StandardScaler()\r\n",
        "    X_train = sc.fit_transform(X_train)\r\n",
        "    X_test = sc.transform(X_test)\r\n",
        "    \r\n",
        "    print(\"Completed Feature Scaling\")\r\n",
        "    \r\n",
        "    from sklearn.neighbors import KNeighborsClassifier\r\n",
        "    # minkowski is for ecledian distance\r\n",
        "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\r\n",
        "    \r\n",
        "    # Model training\r\n",
        "    classifier.fit(X_train, y_train)\r\n",
        "    print(\"Model trained\")\r\n",
        "   \r\n",
        "    y_pred = classifier.predict(X_test)\r\n",
        "    y_prob = classifier.predict_proba(X_test)[:,1]\r\n",
        "    \r\n",
        "    from sklearn.metrics import confusion_matrix\r\n",
        "    \r\n",
        "    cm = confusion_matrix(y_test, y_pred)\r\n",
        "    \r\n",
        "    from sklearn.metrics import accuracy_score\r\n",
        "    \r\n",
        "    model_accuracy = accuracy_score(y_test,y_pred)\r\n",
        "    \r\n",
        "    print(model_accuracy)\r\n",
        "    \r\n",
        "    mlflow.log_metric(\"accuracy\", model_accuracy)\r\n",
        "    mlflow.sklearn.log_model(classifier, \"model\")\r\n",
        "    \r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded training data\n",
            "Completed Feature Scaling\n",
            "Model trained\n",
            "0.8125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SehKnybjFVWu",
        "outputId": "05786c59-09d3-4eea-b5b1-ec2275c24e7b"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.nn import functional as F\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import mlflow\r\n",
        "import mlflow.pytorch\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    \r\n",
        "    mlflow.set_experiment(experiment_name=\"mlflow pytorch demo\")\r\n",
        "    \r\n",
        "    dataset = pd.read_csv('https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/storepurchasedata_large.csv')\r\n",
        "    \r\n",
        "    dataset.describe()\r\n",
        "    \r\n",
        "    dataset.head()\r\n",
        "    \r\n",
        "    X = dataset.iloc[:, :-1].values\r\n",
        "    y = dataset.iloc[:,-1].values\r\n",
        "    \r\n",
        "    from sklearn.model_selection import train_test_split\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =.20,random_state=0)\r\n",
        "    \r\n",
        "    from sklearn.preprocessing import StandardScaler\r\n",
        "    sc = StandardScaler()\r\n",
        "    X_train = sc.fit_transform(X_train)\r\n",
        "    X_test = sc.transform(X_test)\r\n",
        "    \r\n",
        "    Xtrain_ = torch.from_numpy(X_train).float()\r\n",
        "    Xtest_ = torch.from_numpy(X_test).float()\r\n",
        "    \r\n",
        "    Xtrain_\r\n",
        "    \r\n",
        "    ytrain_ = torch.from_numpy(y_train)\r\n",
        "    ytest_ = torch.from_numpy(y_test)\r\n",
        "    \r\n",
        "    ytrain_\r\n",
        "    \r\n",
        "    Xtrain_.shape, ytrain_.shape\r\n",
        "    \r\n",
        "    Xtest_.shape, ytest_.shape\r\n",
        "    \r\n",
        "    input_size=2\r\n",
        "    output_size=2\r\n",
        "    hidden_size=10\r\n",
        "    \r\n",
        "    class Net(nn.Module):\r\n",
        "       def __init__(self):\r\n",
        "           super(Net, self).__init__()\r\n",
        "           self.fc1 = torch.nn.Linear(input_size, hidden_size)\r\n",
        "           self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\r\n",
        "           self.fc3 = torch.nn.Linear(hidden_size, output_size)\r\n",
        "    \r\n",
        "    \r\n",
        "       def forward(self, X):\r\n",
        "           X = torch.relu((self.fc1(X)))\r\n",
        "           X = torch.relu((self.fc2(X)))\r\n",
        "           X = self.fc3(X)\r\n",
        "    \r\n",
        "           return F.log_softmax(X,dim=1)\r\n",
        "    \r\n",
        "    model = Net()\r\n",
        "    \r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\r\n",
        "    loss_fn = nn.NLLLoss()\r\n",
        "    \r\n",
        "    epochs = 50\r\n",
        "    \r\n",
        "    for epoch in range(epochs):\r\n",
        "      optimizer.zero_grad()\r\n",
        "      Ypred = model(Xtrain_)\r\n",
        "      loss = loss_fn(Ypred,  ytrain_)\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "      print('Epoch',epoch, 'loss',loss.item())\r\n",
        "    \r\n",
        "    mlflow.end_run()\r\n",
        "    with mlflow.start_run() as run:\r\n",
        "        mlflow.log_param(\"epochs\", 50)\r\n",
        "        mlflow.pytorch.log_model(model, \"models\")\r\n",
        "        mlflow.log_metric(\"loss\", loss.item())\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 loss 0.6217209100723267\n",
            "Epoch 1 loss 0.6080432534217834\n",
            "Epoch 2 loss 0.5946632027626038\n",
            "Epoch 3 loss 0.5813021063804626\n",
            "Epoch 4 loss 0.5672823190689087\n",
            "Epoch 5 loss 0.552306056022644\n",
            "Epoch 6 loss 0.5361059308052063\n",
            "Epoch 7 loss 0.5190396904945374\n",
            "Epoch 8 loss 0.5011383295059204\n",
            "Epoch 9 loss 0.482537180185318\n",
            "Epoch 10 loss 0.4638012945652008\n",
            "Epoch 11 loss 0.4441814124584198\n",
            "Epoch 12 loss 0.4238114655017853\n",
            "Epoch 13 loss 0.40323126316070557\n",
            "Epoch 14 loss 0.38265877962112427\n",
            "Epoch 15 loss 0.3624744713306427\n",
            "Epoch 16 loss 0.3428744673728943\n",
            "Epoch 17 loss 0.3240891695022583\n",
            "Epoch 18 loss 0.3062521517276764\n",
            "Epoch 19 loss 0.28950539231300354\n",
            "Epoch 20 loss 0.2737556993961334\n",
            "Epoch 21 loss 0.2591138482093811\n",
            "Epoch 22 loss 0.2456398904323578\n",
            "Epoch 23 loss 0.23318041861057281\n",
            "Epoch 24 loss 0.22161489725112915\n",
            "Epoch 25 loss 0.21087764203548431\n",
            "Epoch 26 loss 0.20089055597782135\n",
            "Epoch 27 loss 0.1916988343000412\n",
            "Epoch 28 loss 0.18325361609458923\n",
            "Epoch 29 loss 0.17542989552021027\n",
            "Epoch 30 loss 0.16839665174484253\n",
            "Epoch 31 loss 0.16203369200229645\n",
            "Epoch 32 loss 0.15630745887756348\n",
            "Epoch 33 loss 0.15104475617408752\n",
            "Epoch 34 loss 0.14626097679138184\n",
            "Epoch 35 loss 0.14170807600021362\n",
            "Epoch 36 loss 0.13784807920455933\n",
            "Epoch 37 loss 0.1343560814857483\n",
            "Epoch 38 loss 0.13117752969264984\n",
            "Epoch 39 loss 0.12830764055252075\n",
            "Epoch 40 loss 0.12567631900310516\n",
            "Epoch 41 loss 0.12314759939908981\n",
            "Epoch 42 loss 0.12088014930486679\n",
            "Epoch 43 loss 0.11919553577899933\n",
            "Epoch 44 loss 0.11777381598949432\n",
            "Epoch 45 loss 0.11652923375368118\n",
            "Epoch 46 loss 0.11546287685632706\n",
            "Epoch 47 loss 0.11479450762271881\n",
            "Epoch 48 loss 0.11430934816598892\n",
            "Epoch 49 loss 0.11389116197824478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAZ1YFurGkLj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}