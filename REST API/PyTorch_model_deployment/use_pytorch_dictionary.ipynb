{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVmES9eznedy",
        "outputId": "14ff4690-bcfb-407a-fc61-135efd83eb5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvhaRclnnpbg",
        "outputId": "f4d847ed-a735-4ae2-a5a3-66de255a25dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2020-11-03 14:59:49--  https://github.com/futurexskill/ml-model-deployment/raw/main/customer_buy_state_dict_v1.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/customer_buy_state_dict_v1.zip [following]\n",
            "--2020-11-03 14:59:49--  https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/customer_buy_state_dict_v1.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1660 (1.6K) [application/zip]\n",
            "Saving to: ‘customer_buy_state_dict_v1.zip’\n",
            "\n",
            "customer_buy_state_ 100%[===================>]   1.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-11-03 14:59:49 (32.5 MB/s) - ‘customer_buy_state_dict_v1.zip’ saved [1660/1660]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/futurexskill/ml-model-deployment/raw/main/customer_buy_state_dict_v1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytvZ6yWDnwmO",
        "outputId": "7e3a7577-18b2-4367-a062-5820a703e788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "customer_buy_state_dict_v1.zip\tsample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I_t7FuDnyek",
        "outputId": "acc9b6fa-8c52-4cf3-b44b-0ce8dffd5a2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  customer_buy_state_dict_v1.zip\n",
            "  inflating: customer_buy_state_dict  \n"
          ]
        }
      ],
      "source": [
        "!unzip customer_buy_state_dict_v1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azh8YKcvn2E0",
        "outputId": "fa1c390f-2d67-43b8-b548-92de86bc00a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "customer_buy_state_dict  customer_buy_state_dict_v1.zip  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j8unKY6n32N",
        "outputId": "73fada50-f648-4bd5-d6d6-601fca4dab27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2020-11-03 15:00:39--  https://github.com/futurexskill/ml-model-deployment/raw/main/sc.pickle\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/sc.pickle [following]\n",
            "--2020-11-03 15:00:39--  https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/sc.pickle\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 502 [application/octet-stream]\n",
            "Saving to: ‘sc.pickle’\n",
            "\n",
            "sc.pickle           100%[===================>]     502  --.-KB/s    in 0s      \n",
            "\n",
            "2020-11-03 15:00:39 (20.8 MB/s) - ‘sc.pickle’ saved [502/502]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/futurexskill/ml-model-deployment/raw/main/sc.pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### the define process starts from here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WVvb6Ydrn8-G"
      },
      "outputs": [],
      "source": [
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6he9UV5Bn_Uj",
        "outputId": "7e100d9d-ed26-4e93-a4bf-bc98c75a2cc0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        }
      ],
      "source": [
        "local_scaler = pickle.load(open('sc.pickle','rb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7a3yRlXeoBPR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "W2gHLnuZoEfT"
      },
      "outputs": [],
      "source": [
        "input_size=2\n",
        "output_size=2\n",
        "hidden_size=10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-HCB_fhXoHXc"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(Net, self).__init__()\n",
        "       self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "       self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
        "       self.fc3 = torch.nn.Linear(hidden_size, output_size)\n",
        "\n",
        "\n",
        "   def forward(self, X):\n",
        "       X = torch.relu((self.fc1(X)))\n",
        "       X = torch.relu((self.fc2(X)))\n",
        "       X = self.fc3(X)\n",
        "\n",
        "       return F.log_softmax(X,dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0YzYeenBoLrZ"
      },
      "outputs": [],
      "source": [
        "new_predictor2 = Net()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2TVYKSioO9e",
        "outputId": "7810cf0d-d80b-4ce4-bb01-ad53daaebd66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_predictor2.load_state_dict(torch.load('customer_buy_state_dict'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5JjFZAYloYDs"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQfSNz7AoRHf",
        "outputId": "19611aa1-ee28-4e89-d554-4c0a026e937d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.1102, -2.2600]], grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_cust_42_50000 = new_predictor2(torch.from_numpy(local_scaler.transform(np.array([[40,20000]]))).float())\n",
        "y_cust_42_50000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOcqCy-soV-D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhjNX0S7Nlbu"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "use_pytorch_dictionary.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
